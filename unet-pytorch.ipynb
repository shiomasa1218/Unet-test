{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f00a5dd0230>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_classes = 2\n",
    "img_height,img_width = 236,236\n",
    "out_height,out_width = 52,52\n",
    "GPU = False\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_layer(layer,size):\n",
    "    _,_,h,w = layer.size()\n",
    "    _,_,_h,_w = size\n",
    "    ph = int((h-_h)/2)\n",
    "    pw = int((w-_w)/2)\n",
    "    return layer[:,:,ph:ph+_h,pw:pw+_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet,self).__init__()\n",
    "        \n",
    "        base = 64\n",
    "        \n",
    "        self.enc1 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = 3 if i == 0 else base\n",
    "            self.enc1.add_module(\"enc1_{}\".format(i+1), torch.nn.Conv2d(f, base, kernel_size=3, padding=0, stride=1))\n",
    "            self.enc1.add_module(\"enc1_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.enc1.add_module(\"enc1_bn_{}\".format(i+1),torch.nn.BatchNorm2d(base))\n",
    "            \n",
    "        self.enc2 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base if i == 0 else base*2\n",
    "            self.enc2.add_module(\"enc2_{}\".format(i+1), torch.nn.Conv2d(f, base*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.enc2.add_module(\"enc2_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.enc2.add_module(\"enc2_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2))\n",
    "            \n",
    "        self.enc3 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2 if i == 0 else base*2*2\n",
    "            self.enc3.add_module(\"enc3_{}\".format(i+1), torch.nn.Conv2d(f, base*2*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.enc3.add_module(\"enc3_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.enc3.add_module(\"enc3_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2*2))\n",
    "        \n",
    "        self.enc4 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2*2 if i == 0 else base*2*2*2\n",
    "            self.enc4.add_module(\"enc4_{}\".format(i+1), torch.nn.Conv2d(f, base*2*2*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.enc4.add_module(\"enc4_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.enc4.add_module(\"enc4_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2*2*2))\n",
    "\n",
    "        self.enc5 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2*2*2 if i == 0 else base*2*2*2*2\n",
    "            self.enc5.add_module(\"enc5_{}\".format(i+1), torch.nn.Conv2d(f, base*2*2*2*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.enc5.add_module(\"enc5_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.enc5.add_module(\"enc5_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2*2*2*2))\n",
    "            \n",
    "        self.tconv4 = torch.nn.ConvTranspose2d(base*2*2*2*2, base*2*2*2, kernel_size=2, stride=2)\n",
    "        self.tconv4_bn = torch.nn.BatchNorm2d(base*2*2*2)\n",
    "        \n",
    "        self.dec4 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2*2*2*2 if i == 0 else base*2*2*2\n",
    "            self.dec4.add_module(\"dec4_{}\".format(i+1), torch.nn.Conv2d(f,base*2*2*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.dec4.add_module(\"dec4_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.dec4.add_module(\"dec4_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2*2*2))\n",
    "        \n",
    "        self.tconv3 = torch.nn.ConvTranspose2d(base*2*2*2, base*2*2, kernel_size=2, stride=2)\n",
    "        self.tconv3_bn = torch.nn.BatchNorm2d(base*2*2)\n",
    "        \n",
    "        self.dec3 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2*2*2 if i == 0 else base*2*2\n",
    "            self.dec3.add_module(\"dec3_{}\".format(i+1), torch.nn.Conv2d(f, base*2*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.dec3.add_module(\"dec3_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.dec3.add_module(\"dec3_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2*2))\n",
    "            \n",
    "        self.tconv2 = torch.nn.ConvTranspose2d(base*2*2, base*2, kernel_size=3, stride=2)\n",
    "        self.tconv2_bn = torch.nn.BatchNorm2d(base*2)\n",
    "        \n",
    "        self.dec2 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2*2 if i == 0 else base*2\n",
    "            self.dec2.add_module(\"dec2_{}\".format(i+1), torch.nn.Conv2d(f, base*2, kernel_size=3, padding=0, stride=1))\n",
    "            self.dec2.add_module(\"dec2_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.dec2.add_module(\"dec2_bn_{}\".format(i+1), torch.nn.BatchNorm2d(base*2))\n",
    "            \n",
    "        self.tconv1 = torch.nn.ConvTranspose2d(base*2, base, kernel_size=3, stride=2)\n",
    "        self.tconv1_bn = torch.nn.BatchNorm2d(base)\n",
    "        \n",
    "        self.dec1 = torch.nn.Sequential()\n",
    "        for i in range(2):\n",
    "            f = base*2 if i == 0 else base\n",
    "            self.dec1.add_module(\"dec1_{}\".format(i+1), torch.nn.Conv2d(f, base, kernel_size=3, padding=0, stride=1))\n",
    "            self.dec1.add_module(\"dec1_relu_{}\".format(i+1), torch.nn.ReLU())\n",
    "            self.dec1.add_module(\"dec1_bn_{}\".format(i+1), troch.nn.BatchNorm2d(base))\n",
    "            \n",
    "        self.out = torch.nn.Conv2d(base, num_classes+1, kernel_size=1, padding=0, stride=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_enc1 = self.enc1(x)\n",
    "        x = F.max_pool2d(x_enc1, 2, stride=2, padding=0)\n",
    "        \n",
    "        x_enc2 = self.enc2(x)\n",
    "        x = F.max_pool2d(x_enc2, 2, stride=2, padding=0)\n",
    "        \n",
    "        x_enc3 = self.enc3(x)\n",
    "        x = F.max_pool2d(x_enc3, 2, stride=2, padding=0)\n",
    "        \n",
    "        x_enc4 = self.enc4(x)\n",
    "        x = F.max_pool2d(x_enc4, 2, stride=2, padding=0)\n",
    "        \n",
    "        x = self.enc5(x)\n",
    "        \n",
    "        x = self.tconv4_bn(self.tconv4(x))\n",
    "        _x = crop_layer(x_enc4, x.size())\n",
    "        x = torch.cat((_x,x), dim=1)\n",
    "        x = self.dec4(x)\n",
    "        \n",
    "        x = self.tconv3_bn(self.tconv3(x))\n",
    "        _x = crop_layer(x_enc3, x.size())\n",
    "        x = torch.cat((_x,x), dim=1)\n",
    "        x = self.dec3(x)\n",
    "        \n",
    "        x = self.tconv2_bn(self.tconv2(x))\n",
    "        _x = crop_layer(x_enc2, x.size())\n",
    "        x = torch.cat((_x,x), dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        x = self.tconv1_bn(self.tconv1(x))\n",
    "        _x = crop_layer(x_enc1, x.size())\n",
    "        x = torch.cat((_x,x), dim=1)\n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        x = self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = {\n",
    "    'akahara':[0,0,128],\n",
    "    'madara':[0,128,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(path, hf=False, vf=False):\n",
    "    xs = []\n",
    "    ts = []\n",
    "    paths = []\n",
    "    \n",
    "    for dir_path in glob(path+'/*'):\n",
    "        for path in glob(dir_path+'/*'):\n",
    "            x = cv2.imread(path)\n",
    "            x = cv2.resize(x, (img_width,img_height)).astype(np.float32)\n",
    "            x /= 255.\n",
    "            x = x[..., ::-1]\n",
    "            xs.append(x)\n",
    "            \n",
    "            gt_path = path.replace(\"images\",\"seg_images\").replace(\".jpg\",\".png\")\n",
    "            gt = cv2.imread(gt_path)\n",
    "            gt = resize(gt,(out_width,out_height), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            t = np.zeros((out_height, out_width), dtype=np.int)\n",
    "            \n",
    "            for i (_,vs) in enumerate(CLS.items()):\n",
    "                ind = (gt[...,0] = vs[0])*(gt[...,1] == vs[1])*(gt[...,2] == vs[2])\n",
    "                t[ind] = i+1\n",
    "                \n",
    "                ts.append(t)\n",
    "                paths.append(path)\n",
    "                \n",
    "                if hf:\n",
    "                    xs.append(x[:,::-1])\n",
    "                    ts.append(t[:,::-1])\n",
    "                    paths.append(path)\n",
    "                    \n",
    "                if vf:\n",
    "                    xs.append(x[::-1])\n",
    "                    ts.append(t[::-1])\n",
    "                    paths.append(path)\n",
    "                    \n",
    "                if hf and vf\n",
    "                    xs.append(x[::-1, ::-1])\n",
    "                    ts.append(t[::-1, ::-1])\n",
    "                    paths.append(path)\n",
    "    \n",
    "    xs = np.array(xs)\n",
    "    ts = np.array(ts)\n",
    "    xs = xs.transpose(0,3,1,2)\n",
    "    return xs, ts, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "    \n",
    "    model = UNet().to(device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.train()\n",
    "    \n",
    "    xs, ts, paths = data_load('Dataset/train/images/', hf=True, vf=True)\n",
    "    \n",
    "    mb = 4\n",
    "    mbi = 0\n",
    "    train_N = len(xs)\n",
    "    train_ind = np.arange(train_N)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(train_ind)\n",
    "    \n",
    "    for i in range(100):\n",
    "        if mbi+mb > train_N:\n",
    "            mb_ind = train_N[mbi:]\n",
    "            np.random.shuffle(train_ind)\n",
    "            mb_ind = np.hstack((mb_ind, train_ind[:(mb - (train_N - mbi))]))\n",
    "            mbi = mb - (train_N - mbi)\n",
    "        else:\n",
    "            mb_ind = train_ind[mbi: mbi+mb]\n",
    "            mbi += mb\n",
    "            \n",
    "        x = torch.tensor(xs[mb_ind], dtype=torch.float).to(device)\n",
    "        t = torch.tensor(ts[mb_ind], dtype=torch.float).to(device)\n",
    "        \n",
    "        # zero_grad: initialization\n",
    "        opt.zero_grad()\n",
    "        y = model(x)\n",
    "        \n",
    "        # permute: like np.transpose\n",
    "        # contiguous : values remapping on contiguous memory region\n",
    "        y = y.permute(0,2,3,1).contiguous()\n",
    "        y = y.view(-1, num_classes+1)\n",
    "        t = t.view(-1)\n",
    "        \n",
    "        y = F.log_softmax(y,dim=1)\n",
    "        loss = torch.nn.CrossentropyLoss()(y,t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        pred = y.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(t.view_as(pred)).sum().item()/ mb / img_height / img_width\n",
    "        \n",
    "        print(\"iter >>\", i+1, \",loss >>\", loss.item(), \",acc >>\",acc)\n",
    "        \n",
    "    torch.save(model.state_dict(),\"cnn.pt\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
